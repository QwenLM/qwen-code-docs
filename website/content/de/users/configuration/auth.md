# Authentifizierung

Qwen Code unterst√ºtzt zwei Authentifizierungsmethoden. W√§hlen Sie diejenige aus, die zu Ihrer gew√ºnschten CLI-Ausf√ºhrung passt:

- **Qwen OAuth (empfohlen)**: Anmeldung mit Ihrem `qwen.ai`-Konto im Browser.
- **API-Schl√ºssel**: Verwendung eines API-Schl√ºssels zur Verbindung mit jedem unterst√ºtzten Anbieter. Flexibler ‚Äì unterst√ºtzt OpenAI, Anthropic, Google GenAI, Alibaba Cloud Bailian und andere kompatible Endpunkte.

![](https://gw.alicdn.com/imgextra/i4/O1CN01yXSXc91uYxJxhJXBF_!!6000000006050-2-tps-2372-916.png)

## üëç Option 1: Qwen OAuth (empfohlen & kostenlos)

Verwenden Sie diese Option, wenn Sie die einfachste Einrichtung w√ºnschen und Qwen-Modelle verwenden.

- **Funktionsweise**: Beim ersten Start √∂ffnet Qwen Code eine Browser-Anmeldeseite. Nach Abschluss des Vorgangs werden die Anmeldeinformationen lokal zwischengespeichert, sodass Sie sich in der Regel nicht erneut anmelden m√ºssen.
- **Voraussetzungen**: Ein `qwen.ai`-Konto + Internetzugang (zumindest f√ºr die erste Anmeldung).
- **Vorteile**: Keine API-Schl√ºsselverwaltung, automatische Aktualisierung der Anmeldeinformationen.
- **Kosten & Kontingent**: Kostenlos, mit einem Kontingent von **60 Anfragen/Minute** und **1.000 Anfragen/Tag**.

Starten Sie die CLI und folgen Sie dem Browser-Ablauf:

```bash
qwen
```

> [!note]
>
> In nicht-interaktiven oder headless-Umgebungen (z.B. CI, SSH, Container) k√∂nnen Sie den OAuth-Browser-Anmeldevorgang in der Regel **nicht** abschlie√üen.  
> Verwenden Sie in diesen F√§llen bitte die API-Schl√ºssel-Authentifizierungsmethode.

## üöÄ Option 2: API-Schl√ºssel (flexibel)

Verwenden Sie diese Option, wenn Sie mehr Flexibilit√§t bez√ºglich des verwendeten Anbieters und Modells w√ºnschen. Unterst√ºtzt mehrere Protokolle und Anbieter, darunter OpenAI, Anthropic, Google GenAI, Alibaba Cloud Bailian, Azure OpenAI, OpenRouter, ModelScope oder einen selbst gehosteten kompatiblen Endpunkt.

### Option 1: Coding Plan (Aliyun Bailian)

Verwenden Sie diese Option, wenn Sie vorhersehbare Kosten mit h√∂heren Nutzungsquoten f√ºr das qwen3-coder-plus Modell w√ºnschen.

- **Funktionsweise**: Abonnieren Sie den Coding Plan mit einem festen monatlichen Preis und konfigurieren Sie anschlie√üend Qwen Code so, dass es den dedizierten Endpunkt und Ihren Abonnement-API-Schl√ºssel verwendet.
- **Voraussetzungen**: Beziehen Sie ein aktives Coding Plan-Abonnement von [Alibaba Cloud Bailian](https://bailian.console.aliyun.com/cn-beijing/?tab=globalset#/efm/coding_plan).
- **Vorteile**: H√∂here Nutzungsquoten, vorhersehbare monatliche Kosten, Zugriff auf das neueste qwen3-coder-plus Modell.
- **Kosten und Quota**: Siehe [Alibaba Cloud Bailian Coding Plan Dokumentation](https://bailian.console.aliyun.com/cn-beijing/?tab=doc#/doc/?type=model&url=3005961).

Geben Sie `qwen` im Terminal ein, um Qwen Code zu starten, geben Sie dann den Befehl `/auth` ein und w√§hlen Sie `API-KEY`

![](https://gw.alicdn.com/imgextra/i4/O1CN01yXSXc91uYxJxhJXBF_!!6000000006050-2-tps-2372-916.png)

Nach der Eingabe w√§hlen Sie `Coding Plan`:

![](https://gw.alicdn.com/imgextra/i4/O1CN01Irk0AD1ebfop69o0r_!!6000000003890-2-tps-2308-830.png)

Geben Sie Ihren `sk-sp-xxxxxxxxx` Schl√ºssel ein und verwenden Sie anschlie√üend den Befehl `/model`, um zwischen allen von Bailian `Coding Plan` unterst√ºtzten Modellen zu wechseln:

![](https://gw.alicdn.com/imgextra/i4/O1CN01fWArmf1kaCEgSmPln_!!6000000004699-2-tps-2304-1374.png)

### Option 2: API-Schl√ºssel von Drittanbietern

Verwenden Sie diese Option, wenn Sie sich mit Drittanbietern wie OpenAI, Anthropic, Google, Azure OpenAI, OpenRouter, ModelScope oder einem selbst gehosteten Endpunkt verbinden m√∂chten.

Das zentrale Konzept ist **Modellanbieter** (`modelProviders`): Qwen Code unterst√ºtzt mehrere API-Protokolle, nicht nur OpenAI. Sie konfigurieren, welche Anbieter und Modelle verf√ºgbar sind, indem Sie die Datei `~/.qwen/settings.json` bearbeiten, und wechseln dann zur Laufzeit mit dem Befehl `/model` zwischen ihnen.

#### Unterst√ºtzte Protokolle

| Protokoll         | `modelProviders`-Schl√ºssel | Umgebungsvariablen                                           | Anbieter                                                                                            |
| ----------------- | -------------------------- | -------------------------------------------------------------- | --------------------------------------------------------------------------------------------------- |
| OpenAI-kompatibel | `openai`                   | `OPENAI_API_KEY`, `OPENAI_BASE_URL`, `OPENAI_MODEL`          | OpenAI, Azure OpenAI, OpenRouter, ModelScope, Alibaba Cloud Bailian, beliebige OpenAI-kompatible Endpunkte |
| Anthropic         | `anthropic`                | `ANTHROPIC_API_KEY`, `ANTHROPIC_BASE_URL`, `ANTHROPIC_MODEL` | Anthropic Claude                                                                                    |
| Google GenAI      | `gemini`                   | `GEMINI_API_KEY`, `GEMINI_MODEL`                             | Google Gemini                                                                                       |
| Google Vertex AI  | `vertex-ai`                | `GOOGLE_API_KEY`, `GOOGLE_MODEL`                             | Google Vertex AI                                                                                    |

#### Schritt 1: Konfigurieren Sie `modelProviders` in `~/.qwen/settings.json`

Definieren Sie, welche Modelle f√ºr jedes Protokoll verf√ºgbar sind. Jeder Modelleintrag ben√∂tigt mindestens eine `id` und einen `envKey` (den Namen der Umgebungsvariablen, die Ihren API-Schl√ºssel enth√§lt).

> [!important]
>
> Es wird empfohlen, `modelProviders` im benutzerspezifischen `~/.qwen/settings.json` zu definieren, um Merge-Konflikte zwischen Projekten und Benutzereinstellungen zu vermeiden.

Bearbeiten Sie `~/.qwen/settings.json` (erstellen Sie die Datei, falls sie nicht existiert):

```json
{
  "modelProviders": {
    "openai": [
      {
        "id": "gpt-4o",
        "name": "GPT-4o",
        "envKey": "OPENAI_API_KEY",
        "baseUrl": "https://api.openai.com/v1"
      }
    ],
    "anthropic": [
      {
        "id": "claude-sonnet-4-20250514",
        "name": "Claude Sonnet 4",
        "envKey": "ANTHROPIC_API_KEY"
      }
    ],
    "gemini": [
      {
        "id": "gemini-2.5-pro",
        "name": "Gemini 2.5 Pro",
        "envKey": "GEMINI_API_KEY"
      }
    ]
  }
}
```

Sie k√∂nnen mehrere Protokolle und Modelle in einer einzigen Konfiguration mischen. Die Felder von `ModelConfig` sind:

| Feld               | Erforderlich | Beschreibung                                                         |
| ------------------ | ------------ | -------------------------------------------------------------------- |
| `id`               | Ja           | Modell-ID, die an die API gesendet wird (z.B. `gpt-4o`, `claude-sonnet-4-20250514`) |
| `name`             | Nein         | Anzeigename im `/model`-Auswahlfeld (Standardwert ist `id`)          |
| `envKey`           | Ja           | Name der Umgebungsvariablen f√ºr den API-Schl√ºssel (z.B. `OPENAI_API_KEY`) |
| `baseUrl`          | Nein         | API-Endpunkt-√úberschreibung (n√ºtzlich f√ºr Proxies oder benutzerdefinierte Endpunkte) |
| `generationConfig` | Nein         | Feinabstimmung von `timeout`, `maxRetries`, `samplingParams`, etc.   |

> [!note]
>
> Zugangsdaten werden **niemals** in `settings.json` gespeichert. Zur Laufzeit werden sie aus der in `envKey` angegebenen Umgebungsvariablen gelesen.

F√ºr das vollst√§ndige `modelProviders`-Schema und erweiterte Optionen wie `generationConfig`, `customHeaders` und `extra_body` siehe [Einstellungsreferenz ‚Üí modelProviders](settings.md#modelproviders).

#### Schritt 2: Umgebungsvariablen festlegen

Qwen Code liest API-Schl√ºssel aus Umgebungsvariablen (angegeben durch `envKey` in Ihrer Modellkonfiguration). Es gibt mehrere M√∂glichkeiten, diese bereitzustellen, die unten von **h√∂chster zu niedrigster Priorit√§t** aufgelistet sind:

**1. Shell-Umgebung / `export` (h√∂chste Priorit√§t)**

Direkt in Ihrem Shell-Profil (`~/.zshrc`, `~/.bashrc`, etc.) oder inline vor dem Start festlegen:

```bash

# Alibaba Dashscope
export DASHSCOPE_API_KEY="sk-..."

# OpenAI / OpenAI-kompatibel
export OPENAI_API_KEY="sk-..."

# Anthropic
export ANTHROPIC_API_KEY="sk-ant-..."
```

# Google GenAI
export GEMINI_API_KEY="AIza..."
```

**2. `.env`-Dateien**

Qwen Code l√§dt automatisch die **erste** `.env`-Datei, die es findet (Variablen werden **nicht** √ºber mehrere Dateien hinweg zusammengef√ºhrt). Es werden nur Variablen geladen, die noch nicht in `process.env` vorhanden sind.

Suchreihenfolge (vom aktuellen Verzeichnis aus, aufsteigend bis `/`):

1. `.qwen/.env` (bevorzugt ‚Äî h√§lt Qwen Code-Variablen von anderen Tools getrennt)
2. `.env`

Wenn nichts gefunden wird, greift es auf Ihr **Home-Verzeichnis** zur√ºck:

3. `~/.qwen/.env`
4. `~/.env`

> [!tip]
>
> `.qwen/.env` wird gegen√ºber `.env` empfohlen, um Konflikte mit anderen Tools zu vermeiden. Einige Variablen (wie `DEBUG` und `DEBUG_MODE`) sind von projektweiten `.env`-Dateien ausgeschlossen, um das Verhalten von Qwen Code nicht zu beeintr√§chtigen.

**3. `settings.json` ‚Üí `env`-Feld (niedrigste Priorit√§t)**

Sie k√∂nnen Umgebungsvariablen auch direkt in `~/.qwen/settings.json` unter dem `env`-Schl√ºssel definieren. Diese werden als **Fallback mit niedrigster Priorit√§t** geladen ‚Äî nur angewendet, wenn eine Variable noch nicht durch die Systemumgebung oder `.env`-Dateien gesetzt wurde.

```json
{
  "env": {
    "DASHSCOPE_API_KEY":"sk-...",
    "OPENAI_API_KEY": "sk-...",
    "ANTHROPIC_API_KEY": "sk-ant-...",
    "GEMINI_API_KEY": "AIza..."
  },
  "modelProviders": {
    ...
  }
}
```

> [!note]
>
> Dies ist n√ºtzlich, wenn Sie alle Konfigurationen (Anbieter + Zugangsdaten) in einer einzigen Datei halten m√∂chten. Beachten Sie jedoch, dass `settings.json` m√∂glicherweise geteilt oder synchronisiert wird ‚Äî bevorzugen Sie `.env`-Dateien f√ºr sensible Geheimnisse.

**Priorit√§tszusammenfassung:**

| Priorit√§t   | Quelle                          | √úberschreibeverhalten                      |
| ----------- | ------------------------------- | ------------------------------------------ |
| 1 (h√∂chste) | CLI-Flags (`--openai-api-key`)  | Gewinnt immer                              |
| 2           | Systemumgebung (`export`, inline) | √úberschreibt `.env` und `settings.env`     |
| 3           | `.env`-Datei                    | Setzt nur, wenn nicht in Systemumgebung    |
| 4 (niedrigste) | `settings.json` ‚Üí `env`       | Setzt nur, wenn nicht in Systemumgebung oder `.env` |

#### Schritt 3: Modelle mit `/model` wechseln

Nachdem Sie Qwen Code gestartet haben, verwenden Sie den Befehl `/model`, um zwischen allen konfigurierten Modellen zu wechseln. Die Modelle sind nach Protokoll gruppiert:

```
/model
```

Der Auswahlmodus zeigt alle Modelle aus Ihrer `modelProviders`-Konfiguration an, gruppiert nach ihrem Protokoll (z.B. `openai`, `anthropic`, `gemini`). Ihre Auswahl wird √ºber Sitzungen hinweg beibehalten.

Sie k√∂nnen Modelle auch direkt mit einem Befehlszeilenargument wechseln, was praktisch ist, wenn Sie mit mehreren Terminals arbeiten.

```bash

# In einem Terminal

qwen --model "qwen3-coder-plus"

# In einem anderen Terminal

qwen --model "qwen3-coder-next"
```

## Sicherheitshinweise

- Committen Sie keine API-Schl√ºssel in das Versionskontrollsystem.
- Verwenden Sie bevorzugt `.qwen/.env` f√ºr projektlokale Geheimnisse (und lassen Sie es au√üen vor von Git).
- Behandeln Sie die Ausgabe Ihres Terminals als sensibel, wenn dort Anmeldeinformationen zur √úberpr√ºfung ausgegeben werden.